experiment_name: llemma-7B-backtranslation
train_path: ../make_data/finetune_splits/docgen_export_train.jsonl
eval_path: ../make_data/finetune_splits/docgen_export_valid.jsonl
lr: 5.0e-5 
warmup_steps: 2_000
weight_decay: 0.01
gradient_clipping: 1.0
train_steps: 20_000
logging_steps: 500
eval_steps: 1_000
save_steps: 5_000
batch_size: 4
accum_steps: 2
model_name: "EleutherAI/llemma_7b"
max_length: 400
